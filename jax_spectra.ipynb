{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a11275-41dd-4f99-8f6d-aa221d2c7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import readfof\n",
    "import readgadget\n",
    "import numpy as np\n",
    "import redshift_space_library as RSL\n",
    "import MAS_library as MASL\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import BFast\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import Pk_library as PKL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4520d911",
   "metadata": {},
   "source": [
    "Load the model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fae1d91-e715-4ff0-8d2f-dfe7ca3423ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model and weights\n",
    "import pickle\n",
    "from UNET_jax_eff import UNET3D_jax_e\n",
    "from collections import defaultdict\n",
    "import optax\n",
    "import joblib\n",
    "\n",
    "BoxSize = 1000.\n",
    "model = UNET3D_jax_e(image_size=256, BoxSize=1000, n_base_filters=9, depth=6, dropout_rate=0.3)\n",
    "\n",
    "\n",
    "CHECKPOINT_PATH = \"train_250_val_130\"\n",
    "# params_file = os.path.join(CHECKPOINT_PATH, \"UNET3D_jax_e/model.pkl\") \n",
    "params_file = os.path.join(CHECKPOINT_PATH, \"UNET3D_jax_e/model.joblib\")# Assuming the parameters are saved as \"model_0.pkl\"\n",
    "\n",
    "\n",
    "with open(params_file, 'rb') as f:\n",
    "    loaded_data = joblib.load(f)\n",
    "    params = loaded_data['params']\n",
    "    batch_stats = loaded_data['batch_stats']\n",
    "\n",
    "def predict(model, params, batch_stats, X):\n",
    "    return model.apply({'params': params, 'batch_stats': batch_stats}, X, mutable=False, training =False)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cda7f-c57a-4c7f-997f-ebd98f5db722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax.numpy.fft import rfftn, irfftn\n",
    "grid = 256\n",
    "def cutfield(delta, BoxSize, grid, maxk_kF):\n",
    "    # Cuts the density field at kmax = maxk_kF * kF \n",
    "    kF = 2 * jnp.pi / BoxSize\n",
    "    cell_size = BoxSize / grid\n",
    "\n",
    "    # Create the k-space grid\n",
    "    kx = 2 * jnp.pi * jnp.fft.fftfreq(grid, cell_size)\n",
    "    ky = 2 * jnp.pi * jnp.fft.fftfreq(grid, cell_size)\n",
    "    kz = 2 * jnp.pi * jnp.fft.rfftfreq(grid, cell_size)\n",
    "    kx, ky, kz = jnp.meshgrid(kx, ky, kz, indexing=\"ij\")\n",
    "    kgrid = jnp.sqrt(kx**2 + ky**2 + kz**2)\n",
    "\n",
    "    # Create a boolean mask for the cut-off\n",
    "    bools = (kgrid >= maxk_kF * kF)\n",
    "\n",
    "    # Apply Fourier Transform, filter and then apply Inverse Fourier Transform\n",
    "    c_fftgrid = rfftn(delta)\n",
    "    c_fftgrid = jnp.where(bools, 0.+0.j, c_fftgrid)\n",
    "    r_fftgrid = irfftn(c_fftgrid)\n",
    "\n",
    "    return r_fftgrid\n",
    "\n",
    "\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "from jax.numpy.fft import rfftn, irfftn\n",
    "\n",
    "# Vectorize cutfield for batch processing\n",
    "batch_cutfield = vmap(cutfield, in_axes=(0, None, None, None))\n",
    "\n",
    "# Assuming y_data is a JAX array and BoxSize, grid are defined\n",
    "batch_size = 10\n",
    "\n",
    "y_data =  np.array([np.load(f\"/scratch/s3487202/Matter_Data/fiducial/0/df_m_256_PCS_fiducial_127_{i}.npy\") for i in tqdm(range(100))])\n",
    "print('data had loaded')\n",
    "# Process each batch and normalize it before moving to the next batch\n",
    "y_data_cut = np.zeros((y_data.shape[0],y_data.shape[1],y_data.shape[2],y_data.shape[3]),dtype=np.float32)\n",
    "for i in range(0, y_data.shape[0], batch_size):\n",
    "    print(i)\n",
    "    batch = y_data[i:i + batch_size]\n",
    "    processed_batch = batch_cutfield(batch, BoxSize, grid, 82.5)\n",
    "\n",
    "    # Normalize the processed batch\n",
    "    processed_batch /= processed_batch.reshape(processed_batch.shape[0], -1).std()\n",
    "    processed_batch = np.array(processed_batch)\n",
    "\n",
    "    y_data_cut[i:i + batch_size] = processed_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6ecd1-5066-4452-8b3f-c3898e3c1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #single example\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger('jax').setLevel(logging.ERROR)\n",
    "\n",
    "# # Filter out specific warning messages\n",
    "# # warnings.filterwarnings(\"ignore\", message=\"Trying algorithm.*is taking a while...\")\n",
    "# # warnings.filterwarnings(\"ignore\", message=\"The operation took.*\")\n",
    "# BoxSize = 1000.\n",
    "# grid = int(256)\n",
    "# Hubble = int(100)\n",
    "# redshift = 0\n",
    "# snapshot_number = 0\n",
    "# typey= 'fiducial'\n",
    "# snapdir = f'/scratch/hb-CosmoGroup/Quijote_Halos/{typey}/5' #folder hosting the catalogue\n",
    "# snapnum = 4   \n",
    "\n",
    "# delta_z = np.array(y_data[0])\n",
    "# axis = 2\n",
    "# Pks_32_z_s = BFast.Pk(delta_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "# Bks_32_z_s = BFast.Bk(delta_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "# numbers = list(range(100)) \n",
    "\n",
    "# Pk_z0_array_z = np.zeros((len(numbers), Pks_32_z_s.shape[0], Pks_32_z_s.shape[1]))\n",
    "# Bk_z0_array_z = np.zeros((len(numbers), Bks_32_z_s.shape[0], Bks_32_z_s.shape[1]))\n",
    "# for num in numbers:\n",
    "#     print(num)\n",
    "#     delta_z = np.array(y_data_cut[num])\n",
    "\n",
    "# #rotate the fields\n",
    "# # delta_x_rot = np.transpose(delta_x, (1, 2, 0))\n",
    "# # delta_y_rot = np.transpose(delta_y, (2, 0, 1))\n",
    "\n",
    "# #predict and calculate power and bispectrum of pre and post?\n",
    "\n",
    "# # pred_x = np.squeeze(predict(model,params,batch_stats,delta_x_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "# # pred_y = np.squeeze(predict(model,params,batch_stats,delta_y_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "# # pred_z = np.squeeze(predict(model,params,batch_stats,delta_z[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "# # print(delta_z.shape)\n",
    "\n",
    "# #do not save the fields because of memory\n",
    "# # calculate power and bispectra for fields\n",
    "# # Pks_32_x_s = BFast.Pk(delta_x_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "# # Pks_32_y_s = BFast.Pk(delta_y_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "#     Pks_32_z_s = BFast.Pk(delta_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "\n",
    "# # Pks_32_pred_x_s = BFast.Pk(pred_x,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "# # Pks_32_pred_y_s = BFast.Pk(pred_y,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "# # Pks_32_pred_z_s = BFast.Pk(pred_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "\n",
    "# # Bks_32_x_s = BFast.Bk(delta_x_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "# # Bks_32_y_s = BFast.Bk(delta_y_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "#     Bks_32_z_s = BFast.Bk(delta_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "\n",
    "# # Bks_32_pred_x_s = BFast.Bk(pred_x,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "# # Bks_32_pred_y_s = BFast.Bk(pred_y,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "# # Bks_32_pred_z_s = BFast.Bk(pred_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "#     Pk_z0_array_z[num] = Pks_32_z_s\n",
    "#     Bk_z0_array_z[num] = Bks_32_z_s\n",
    "\n",
    "\n",
    "# np.save(f\"/scratch/s3487202/Results/power_spectrum/y_data_{typey}.npy\", Pk_z0_array_z)\n",
    "# np.save(f\"/scratch/s3487202/Results/bispectrum/y_data_{typey}.npy\", Bk_z0_array_z)\n",
    "# print(Pk_z0_array_z.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b02ce",
   "metadata": {},
   "source": [
    "single example to get the eventual shape of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d544521-6db2-4c4d-b1a7-937939c70c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#single example\n",
    "\n",
    "import logging\n",
    "logging.getLogger('jax').setLevel(logging.ERROR)\n",
    "\n",
    "# Filter out specific warning messages\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Trying algorithm.*is taking a while...\")\n",
    "# warnings.filterwarnings(\"ignore\", message=\"The operation took.*\")\n",
    "BoxSize = 1000.\n",
    "grid = int(256)\n",
    "Hubble = int(100)\n",
    "redshift = 0\n",
    "snapshot_number = 0\n",
    "typey= 'fiducial'\n",
    "snapdir = f'/scratch/hb-CosmoGroup/Quijote_Halos/{typey}/5' #folder hosting the catalogue\n",
    "snapnum = 4   \n",
    "# read the halo catalogue\n",
    "\n",
    "FoF = readfof.FoF_catalog(snapdir, snapnum, long_ids=False, swap=False, SFR=False, read_IDs=False)\n",
    "pos_h = FoF.GroupPos / 1e3\n",
    "vel_h = FoF.GroupVel*(1.0+redshift) #Halo peculiar velocities in km/s\n",
    "\n",
    "#read the void catalogue\n",
    "\n",
    "# Move particles to redshift-space\n",
    "axis_list = [0, 1, 2]\n",
    "# axis_list = [2] # z axis because void data is distorted in z axis\n",
    "delta_fields = []\n",
    "mean_fields = []\n",
    "\n",
    "for axis in axis_list:\n",
    "    RSL.pos_redshift_space(pos_h, vel_h, BoxSize, Hubble, redshift, axis)\n",
    "    delta = np.zeros((grid, grid, grid), dtype=np.float32)\n",
    "    #MASL.MA(pos_h_d, delta, BoxSize, MAS, verbose=verbose)\n",
    "    MASL.MA(pos_h, delta, BoxSize, 'PCS', verbose=False)\n",
    "    # mean_fields.append(np.mean(delta, dtype=np.float32))\n",
    "    delta /= np.mean(delta, dtype=np.float32)\n",
    "    delta -= 1.0\n",
    "    delta_fields.append(delta)\n",
    "\n",
    "# Separate the density fields for x, y, and z axes\n",
    "delta_x,delta_y,delta_z = delta_fields\n",
    "\n",
    "delta_x = np.array(delta_x)\n",
    "delta_y = np.array(delta_y)\n",
    "delta_z = np.array(delta_z)\n",
    "\n",
    "#rotate the fields\n",
    "delta_x_rot = np.transpose(delta_x, (1, 2, 0))\n",
    "delta_y_rot = np.transpose(delta_y, (2, 0, 1))\n",
    "\n",
    "#predict and calculate power and bispectrum of pre and post?\n",
    "\n",
    "pred_x = np.squeeze(predict(model,params,batch_stats,delta_x_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "pred_y = np.squeeze(predict(model,params,batch_stats,delta_y_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "pred_z = np.squeeze(predict(model,params,batch_stats,delta_z[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "print(delta_z.shape)\n",
    "\n",
    "#do not save the fields because of memory\n",
    "# calculate power and bispectra for fields\n",
    "Pks_32_x_s = BFast.Pk(delta_x_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "Pks_32_y_s = BFast.Pk(delta_y_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "Pks_32_z_s = BFast.Pk(delta_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "\n",
    "Pks_32_pred_x_s = BFast.Pk(pred_x,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "Pks_32_pred_y_s = BFast.Pk(pred_y,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "Pks_32_pred_z_s = BFast.Pk(pred_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "\n",
    "Bks_32_x_s = BFast.Bk(delta_x_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "Bks_32_y_s = BFast.Bk(delta_y_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "Bks_32_z_s = BFast.Bk(delta_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "\n",
    "Bks_32_pred_x_s = BFast.Bk(pred_x,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "Bks_32_pred_y_s = BFast.Bk(pred_y,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "Bks_32_pred_z_s = BFast.Bk(pred_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "\n",
    "print(Pks_32_pred_x_s.shape)\n",
    "print(Bks_32_pred_x_s.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc51e3",
   "metadata": {},
   "source": [
    "Code to calculate the spectra of the derivatives( non fiducial cosmology simulations in my case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb024d-e9bc-437e-aab4-da537b647339",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#for derivatives\n",
    "BoxSize = 1000.\n",
    "grid = int(256)\n",
    "Hubble = int(100)\n",
    "redshift = 0\n",
    "# numbers = list(range(81)) \n",
    "\n",
    "snapnum = 4\n",
    "kF = 2*np.pi/BoxSize\n",
    "threads=8\n",
    "axis =2\n",
    "\n",
    "numbers = list(range(500)) \n",
    "Pk_z0_array_x = np.zeros((len(numbers),  Pks_32_x_s.shape[0],Pks_32_x_s.shape[1],))\n",
    "Pk_z127_rec_array_x = np.zeros((len(numbers), Pks_32_pred_x_s.shape[0],Pks_32_pred_x_s.shape[1],))\n",
    "\n",
    "Pk_z0_array_y = np.zeros((len(numbers), Pks_32_y_s.shape[0], Pks_32_y_s.shape[1]))\n",
    "Pk_z127_rec_array_y = np.zeros((len(numbers), Pks_32_pred_y_s.shape[0], Pks_32_pred_y_s.shape[1]))\n",
    "\n",
    "Pk_z0_array_z = np.zeros((len(numbers), Pks_32_z_s.shape[0], Pks_32_z_s.shape[1]))\n",
    "Pk_z127_rec_array_z = np.zeros((len(numbers), Pks_32_pred_z_s.shape[0], Pks_32_pred_z_s.shape[1]))\n",
    "\n",
    "Bk_z0_array_x = np.zeros((len(numbers),  Bks_32_x_s.shape[0],Bks_32_x_s.shape[1],))\n",
    "Bk_z127_rec_array_x = np.zeros((len(numbers), Bks_32_pred_x_s.shape[0],Bks_32_pred_x_s.shape[1],))\n",
    "\n",
    "Bk_z0_array_y = np.zeros((len(numbers), Bks_32_y_s.shape[0], Bks_32_y_s.shape[1]))\n",
    "Bk_z127_rec_array_y = np.zeros((len(numbers), Bks_32_pred_y_s.shape[0], Bks_32_pred_y_s.shape[1]))\n",
    "\n",
    "Bk_z0_array_z = np.zeros((len(numbers), Bks_32_z_s.shape[0], Bks_32_z_s.shape[1]))\n",
    "Bk_z127_rec_array_z = np.zeros((len(numbers), Bks_32_pred_z_s.shape[0], Bks_32_pred_z_s.shape[1]))\n",
    "# typey_list = ['Ob2_p','Om_m','Om_p','OR_LSS_m','OR_LSS_p','s8_m','s8_p']\n",
    "typey_list = ['EQ_m','EQ_p','h_m','h_p','LC_m','LC_p']\n",
    "# typey = 'EQ_m'\n",
    "for typey in typey_list:\n",
    "    print(f'loop {typey} starts ')\n",
    "    for num in numbers:\n",
    "        print(num)\n",
    "        snapshot_number = num\n",
    "        snapdir = f'/scratch/hb-CosmoGroup/Quijote_Halos/{typey}/{snapshot_number}' #folder hosting the catalogue\n",
    "       \n",
    "        # read the halo catalogue\n",
    "    \n",
    "        FoF = readfof.FoF_catalog(snapdir, snapnum, long_ids=False, swap=False, SFR=False, read_IDs=False)\n",
    "        pos_h = FoF.GroupPos / 1e3\n",
    "        vel_h = FoF.GroupVel*(1.0+redshift) #Halo peculiar velocities in km/s\n",
    "    \n",
    "        #read the void catalogue\n",
    "    \n",
    "        # Move particles to redshift-space\n",
    "        axis_list = [0, 1, 2]\n",
    "        # axis_list = [2] # z axis because void data is distorted in z axis\n",
    "        delta_fields = []\n",
    "        mean_fields = []\n",
    "        for axis in axis_list:\n",
    "\n",
    "            # Create a copy of pos_h for each axis\n",
    "            pos_h_axis = pos_h.copy()\n",
    "            RSL.pos_redshift_space(pos_h_axis, vel_h, BoxSize, Hubble, redshift, axis)\n",
    "            delta = np.zeros((grid, grid, grid), dtype=np.float32)\n",
    "            MASL.MA(pos_h_axis, delta, BoxSize, 'PCS', verbose=False)\n",
    "            delta /= np.mean(delta, dtype=np.float32)\n",
    "            delta -= 1.0\n",
    "            delta_fields.append(delta)\n",
    "        \n",
    "        \n",
    "        # Separate the density fields for x, y, and z axes\n",
    "        delta_x,delta_y,delta_z = delta_fields\n",
    "        # print(delta_z.shape)\n",
    "        delta_x = np.array(delta_x)\n",
    "        delta_y = np.array(delta_y)\n",
    "        delta_z = np.array(delta_z)\n",
    "    \n",
    "        #rotate the fields\n",
    "        delta_x_rot = np.transpose(delta_x, (1, 2, 0))\n",
    "        delta_y_rot = np.transpose(delta_y, (2, 0, 1))\n",
    "    \n",
    "        \n",
    "        #predict and calculate power and bispectrum of pre and post?\n",
    "        axis = 2\n",
    "        pred_x = np.squeeze(predict(model,params,batch_stats,delta_x_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "        pred_y = np.squeeze(predict(model,params,batch_stats,delta_y_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "        pred_z = np.squeeze(predict(model,params,batch_stats,delta_z[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "            \n",
    "        #do not save the fields because of memory\n",
    "        # calculate power and bispectra for fields\n",
    "        Pks_32_x = BFast.Pk(delta_x_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        Pks_32_y = BFast.Pk(delta_y_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        Pks_32_z = BFast.Pk(delta_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "    \n",
    "        Pks_32_pred_x = BFast.Pk(pred_x,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        Pks_32_pred_y = BFast.Pk(pred_y,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        Pks_32_pred_z = BFast.Pk(pred_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "    \n",
    "        Bks_32_x = BFast.Bk(delta_x_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        Bks_32_y = BFast.Bk(delta_y_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        Bks_32_z = BFast.Bk(delta_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "    \n",
    "        Bks_32_pred_x = BFast.Bk(pred_x,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        Bks_32_pred_y = BFast.Bk(pred_y,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        Bks_32_pred_z = BFast.Bk(pred_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "    \n",
    "    \n",
    "        Pk_z0_array_x[num]= Pks_32_x\n",
    "        Pk_z127_rec_array_x[num] = Pks_32_pred_x\n",
    "    \n",
    "        Pk_z0_array_y[num] = Pks_32_y\n",
    "        Pk_z127_rec_array_y[num] = Pks_32_pred_y\n",
    "    \n",
    "        Pk_z0_array_z[num] = Pks_32_z\n",
    "        Pk_z127_rec_array_z[num] = Pks_32_pred_z\n",
    "    \n",
    "        Bk_z0_array_x[num] = Bks_32_x\n",
    "        Bk_z127_rec_array_x[num] = Bks_32_pred_x\n",
    "    \n",
    "        Bk_z0_array_y[num] = Bks_32_y\n",
    "        Bk_z127_rec_array_y[num] = Bks_32_pred_y\n",
    "    \n",
    "        Bk_z0_array_z[num] = Bks_32_z\n",
    "        Bk_z127_rec_array_z[num] = Bks_32_pred_z\n",
    "    print(f'loop {typey} done')\n",
    "    \n",
    "    # Concatenate _array_x with _array_y and _array_z\n",
    "    Pk_z0_array_combined = np.concatenate([Pk_z0_array_x, Pk_z0_array_y, Pk_z0_array_z], axis=0)\n",
    "    Pk_z127_rec_array_combined = np.concatenate([Pk_z127_rec_array_x, Pk_z127_rec_array_y, Pk_z127_rec_array_z], axis=0)\n",
    "    \n",
    "    Bk_z0_array_combined = np.concatenate([Bk_z0_array_x, Bk_z0_array_y, Bk_z0_array_z], axis=0)\n",
    "    Bk_z127_rec_array_combined = np.concatenate([Bk_z127_rec_array_x, Bk_z127_rec_array_y, Bk_z127_rec_array_z], axis=0)\n",
    "    \n",
    "    # for derivatives\n",
    "    np.save(f\"/scratch/s3487202/Results/power_spectrum/halo_data_z0_{typey}.npy\", Pk_z0_array_combined)\n",
    "    np.save(f\"/scratch/s3487202/Results/power_spectrum/rec_z127_{typey}.npy\", Pk_z127_rec_array_combined)\n",
    "    np.save(f\"/scratch/s3487202/Results/bispectrum/halo_data_z0_{typey}.npy\", Bk_z0_array_combined)\n",
    "    np.save(f\"/scratch/s3487202/Results/bispectrum/rec_z127_{typey}.npy\", Bk_z127_rec_array_combined)\n",
    "\n",
    "    #for fiducial\n",
    "    # np.save(f\"/scratch/s3487202/Results/power_spectrum/halo_data_z0_{typey}_0-2499.npy\", Pk_z0_array_z)\n",
    "    # np.save(f\"/scratch/s3487202/Results/power_spectrum/rec_z127_{typey}_0-2499.npy\", Pk_z127_rec_array_z)\n",
    "    # np.save(f\"/scratch/s3487202/Results/bispectrum/halo_data_z0_{typey}_0-2499.npy\", Bk_z0_array_z)\n",
    "    # np.save(f\"/scratch/s3487202/Results/bispectrum/rec_z127_{typey}_0-2499.npy\", Bk_z127_rec_array_z)\n",
    "    print(f'{typey} saved')\n",
    "print(Bk_z0_array_combined.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2afe37",
   "metadata": {},
   "source": [
    "Code for calculating the spectra of the fiducial simulations in batches, used for the covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2caa9d9-fa18-4df7-b3e1-155a54a7d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#for fiducial\n",
    "BoxSize = 1000.\n",
    "grid = int(256)\n",
    "Hubble = int(100)\n",
    "redshift = 0\n",
    "\n",
    "\n",
    "snapnum = 4\n",
    "kF = 2*np.pi/BoxSize\n",
    "threads=8\n",
    "axis =2\n",
    "\n",
    "numbers = list(range(10000,15000)) \n",
    "# Pk_z0_array_x = np.zeros((len(numbers),  Pks_32_x_s.shape[0],Pks_32_x_s.shape[1],))\n",
    "# Pk_z127_rec_array_x = np.zeros((len(numbers), Pks_32_pred_x_s.shape[0],Pks_32_pred_x_s.shape[1],))\n",
    "\n",
    "# Pk_z0_array_y = np.zeros((len(numbers), Pks_32_y_s.shape[0], Pks_32_y_s.shape[1]))\n",
    "# Pk_z127_rec_array_y = np.zeros((len(numbers), Pks_32_pred_y_s.shape[0], Pks_32_pred_y_s.shape[1]))\n",
    "\n",
    "Pk_z0_array_z = np.zeros((len(numbers), Pks_32_z_s.shape[0], Pks_32_z_s.shape[1]))\n",
    "Pk_z127_rec_array_z = np.zeros((len(numbers), Pks_32_pred_z_s.shape[0], Pks_32_pred_z_s.shape[1]))\n",
    "\n",
    "# Bk_z0_array_x = np.zeros((len(numbers),  Bks_32_x_s.shape[0],Bks_32_x_s.shape[1],))\n",
    "# Bk_z127_rec_array_x = np.zeros((len(numbers), Bks_32_pred_x_s.shape[0],Bks_32_pred_x_s.shape[1],))\n",
    "\n",
    "# Bk_z0_array_y = np.zeros((len(numbers), Bks_32_y_s.shape[0], Bks_32_y_s.shape[1]))\n",
    "# Bk_z127_rec_array_y = np.zeros((len(numbers), Bks_32_pred_y_s.shape[0], Bks_32_pred_y_s.shape[1]))\n",
    "\n",
    "Bk_z0_array_z = np.zeros((len(numbers), Bks_32_z_s.shape[0], Bks_32_z_s.shape[1]))\n",
    "Bk_z127_rec_array_z = np.zeros((len(numbers), Bks_32_pred_z_s.shape[0], Bks_32_pred_z_s.shape[1]))\n",
    "# typey_list = ['Ob2_p','Om_m','Om_p','OR_LSS_m','OR_LSS_p','s8_m','s8_p']\n",
    "typey_list = ['fiducial']\n",
    "# typey = 'EQ_p'\n",
    "for typey in typey_list:\n",
    "    print(f'loop {typey} starts ')\n",
    "    for num in numbers:\n",
    "        print(num)\n",
    "        snapshot_number = num\n",
    "        snapdir = f'/scratch/hb-CosmoGroup/Quijote_Halos/{typey}/{snapshot_number}' #folder hosting the catalogue\n",
    "       \n",
    "        # read the halo catalogue\n",
    "    \n",
    "        FoF = readfof.FoF_catalog(snapdir, snapnum, long_ids=False, swap=False, SFR=False, read_IDs=False)\n",
    "        pos_h = FoF.GroupPos / 1e3\n",
    "        vel_h = FoF.GroupVel*(1.0+redshift) #Halo peculiar velocities in km/s\n",
    "    \n",
    "        #read the void catalogue\n",
    "    \n",
    "        # Move particles to redshift-space\n",
    "        # axis_list = [0, 1, 2]\n",
    "        axis_list = [2] # z axis because void data is distorted in z axis\n",
    "        delta_fields = []\n",
    "        mean_fields = []\n",
    "        # for axis in axis_list:\n",
    "        RSL.pos_redshift_space(pos_h, vel_h, BoxSize, Hubble, redshift, axis)\n",
    "        delta = np.zeros((grid, grid, grid), dtype=np.float32)\n",
    "        #MASL.MA(pos_h_d, delta, BoxSize, MAS, verbose=verbose)\n",
    "        MASL.MA(pos_h, delta, BoxSize, 'PCS', verbose=False)\n",
    "        # mean_fields.append(np.mean(delta, dtype=np.float32))\n",
    "        delta /= np.mean(delta, dtype=np.float32)\n",
    "        delta -= 1.0\n",
    "        delta_z = delta\n",
    "        # delta_fields.append(delta)\n",
    "        \n",
    "        \n",
    "        # Separate the density fields for x, y, and z axes\n",
    "        #delta_x,delta_y,delta_z = delta_fields\n",
    "        # delta_z = delta_fields\n",
    "    \n",
    "        # delta_x = np.array(delta_x)\n",
    "        # delta_y = np.array(delta_y)\n",
    "        delta_z = np.array(delta_z)\n",
    " \n",
    "        #rotate the fields\n",
    "        # delta_x_rot = np.transpose(delta_x, (1, 2, 0))\n",
    "        # delta_y_rot = np.transpose(delta_y, (2, 0, 1))\n",
    "    \n",
    "        \n",
    "        #predict and calculate power and bispectrum of pre and post?\n",
    "        axis = 2\n",
    "        # pred_x = np.squeeze(predict(model,params,batch_stats,delta_x_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "        # pred_y = np.squeeze(predict(model,params,batch_stats,delta_y_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "        pred_z = np.squeeze(predict(model,params,batch_stats,delta_z[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "            \n",
    "        #do not save the fields because of memory\n",
    "        # calculate power and bispectra for fields\n",
    "        # Pks_32_x = BFast.Pk(delta_x_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        # Pks_32_y = BFast.Pk(delta_y_rot,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        Pks_32_z = BFast.Pk(delta_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "    \n",
    "        # Pks_32_pred_x = BFast.Pk(pred_x,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        # Pks_32_pred_y = BFast.Pk(pred_y,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "        Pks_32_pred_z = BFast.Pk(pred_z,1000.,axis,MAS='PCS',left_inclusive=True,precision='float32')\n",
    "    \n",
    "        # Bks_32_x = BFast.Bk(delta_x_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        # Bks_32_y = BFast.Bk(delta_y_rot,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        Bks_32_z = BFast.Bk(delta_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "    \n",
    "        # Bks_32_pred_x = BFast.Bk(pred_x,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        # Bks_32_pred_y = BFast.Bk(pred_y,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "        Bks_32_pred_z = BFast.Bk(pred_z,BoxSize,3.,3.,27,'All',MAS='PCS',fast=True,precision='float32',verbose=False)\n",
    "    \n",
    "    \n",
    "        # Pk_z0_array_x[num]= Pks_32_x\n",
    "        # Pk_z127_rec_array_x[num] = Pks_32_pred_x\n",
    "    \n",
    "        # Pk_z0_array_y[num] = Pks_32_y\n",
    "        # Pk_z127_rec_array_y[num] = Pks_32_pred_y\n",
    "    \n",
    "        Pk_z0_array_z[num-10000] = Pks_32_z\n",
    "        Pk_z127_rec_array_z[num-10000] = Pks_32_pred_z\n",
    "    \n",
    "        # Bk_z0_array_x[num] = Bks_32_x\n",
    "        # Bk_z127_rec_array_x[num] = Bks_32_pred_x\n",
    "    \n",
    "        # Bk_z0_array_y[num] = Bks_32_y\n",
    "        # Bk_z127_rec_array_y[num] = Bks_32_pred_y\n",
    "    \n",
    "        Bk_z0_array_z[num-10000] = Bks_32_z\n",
    "        Bk_z127_rec_array_z[num-10000] = Bks_32_pred_z\n",
    "    print(f'loop {typey} done')\n",
    "    \n",
    "    # Concatenate _array_x with _array_y and _array_z\n",
    "    # Pk_z0_array_combined = np.concatenate([Pk_z0_array_x, Pk_z0_array_y, Pk_z0_array_z], axis=0)\n",
    "    # Pk_z127_rec_array_combined = np.concatenate([Pk_z127_rec_array_x, Pk_z127_rec_array_y, Pk_z127_rec_array_z], axis=0)\n",
    "    \n",
    "    # Bk_z0_array_combined = np.concatenate([Bk_z0_array_x, Bk_z0_array_y, Bk_z0_array_z], axis=0)\n",
    "    # Bk_z127_rec_array_combined = np.concatenate([Bk_z127_rec_array_x, Bk_z127_rec_array_y, Bk_z127_rec_array_z], axis=0)\n",
    "    \n",
    "    #for derivatives\n",
    "    # np.save(f\"/scratch/s3487202/Results/power_spectrum/halo_data_z0_{typey}.npy\", Pk_z0_array_combined)\n",
    "    # np.save(f\"/scratch/s3487202/Results/power_spectrum/rec_z127_{typey}.npy\", Pk_z127_rec_array_combined)\n",
    "    # np.save(f\"/scratch/s3487202/Results/bispectrum/halo_data_z0_{typey}.npy\", Bk_z0_array_combined)\n",
    "    # np.save(f\"/scratch/s3487202/Results/bispectrum/rec_z127_{typey}.npy\", Bk_z127_rec_array_combined)\n",
    "\n",
    "    #for fiducial\n",
    "    np.save(f\"/scratch/s3487202/Results/power_spectrum/halo_data_z0_{typey}_10000-14999.npy\", Pk_z0_array_z)\n",
    "    np.save(f\"/scratch/s3487202/Results/power_spectrum/rec_z127_{typey}_10000-14999.npy\", Pk_z127_rec_array_z)\n",
    "    np.save(f\"/scratch/s3487202/Results/bispectrum/halo_data_z0_{typey}_10000-14999.npy\", Bk_z0_array_z)\n",
    "    np.save(f\"/scratch/s3487202/Results/bispectrum/rec_z127_{typey}_10000-14999.npy\", Bk_z127_rec_array_z)\n",
    "    print(f'{typey} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440080aa-9538-4ad2-9bed-3049d6c75adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"/scratch/s3487202/Results/power_spectrum/halo_data_z0_{typey}.npy\", Pk_z0_array_combined)\n",
    "np.save(f\"/scratch/s3487202/Results/power_spectrum/rec_z127_{typey}.npy\", Pk_z127_rec_array_combined)\n",
    "np.save(f\"/scratch/s3487202/Results/bispectrum/halo_data_z0_{typey}.npy\", Bk_z0_array_combined)\n",
    "np.save(f\"/scratch/s3487202/Results/bispectrum/rec_z127_{typey}.npy\", Bk_z127_rec_array_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d175a20-1f64-4393-835a-b22b97bd2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk_z0_array_combined[0])\n",
    "print(Pk_z127_rec_array_combined[0])\n",
    "print(Pk_z127_rec_array_combined[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673241d9-94f8-48c1-b005-617ee6885f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# def initialize_arrays(shape, dtype=np.float32):\n",
    "#     return np.zeros((len(numbers), *shape), dtype=dtype)\n",
    "\n",
    "# def process_catalog(snapshot_dir, snapshot_number, BoxSize, grid, redshift, Hubble):\n",
    "#     FoF = readfof.FoF_catalog(snapshot_dir, snapshot_number, long_ids=False, swap=False, SFR=False, read_IDs=False)\n",
    "#     pos_h = FoF.GroupPos / 1e3\n",
    "#     vel_h = FoF.GroupVel * (1.0 + redshift)\n",
    "#     return pos_h, vel_h\n",
    "\n",
    "# def calculate_spectra(delta_fields, BoxSize, axis):\n",
    "#     pks, bks = [], []\n",
    "#     rotation_map = {\n",
    "#         0: (1, 2, 0),  # x-axis\n",
    "#         1: (2, 0, 1),  # y-axis\n",
    "#         2: (0, 1, 2)   # z-axis\n",
    "#     }\n",
    "#     for i, field in enumerate(delta_fields):\n",
    " \n",
    "#         field_rot = np.transpose(field, rotation_map[i])\n",
    "#         pks.append(BFast.Pk(field_rot, BoxSize, 2, MAS='PCS', left_inclusive=True, precision='float32'))\n",
    "#         bks.append(BFast.Bk(field_rot, BoxSize, 3., 3., 27, 'All', MAS='PCS', fast=True, precision='float32', verbose=False))\n",
    "#     return pks, bks\n",
    "\n",
    "# def predict_and_calculate_spectra(model, params, batch_stats, delta_fields):\n",
    "#     spectra = []\n",
    "#     for i, delta in enumerate(delta_fields):\n",
    " \n",
    "#         rotation_map = {\n",
    "#             0: (1, 2, 0),  # x-axis\n",
    "#             1: (2, 0, 1),  # y-axis\n",
    "#             2: (0, 1, 2)   # z-axis\n",
    "#         }\n",
    "#         delta_rot = np.transpose(delta, rotation_map[i])\n",
    "#         pred = np.squeeze(predict(model, params, batch_stats, delta_rot[np.newaxis,:,:,:,np.newaxis])[0,:,:,:])\n",
    "#         pks = BFast.Pk(pred, 1000., 2, MAS='PCS', left_inclusive=True, precision='float32')\n",
    "#         bks = BFast.Bk(pred, 1000., 3., 3., 27, 'All', MAS='PCS', fast=True, precision='float32', verbose=False)\n",
    "#         spectra.append((pks, bks))\n",
    "#     return spectra\n",
    "\n",
    "# def apply_redshift_space_distortion(pos_h, vel_h, BoxSize, Hubble, redshift, grid, axis_list):\n",
    "#     delta_fields = []\n",
    "#     for axis in axis_list:\n",
    "#         delta = np.zeros((grid, grid, grid), dtype=np.float32)\n",
    "#         RSL.pos_redshift_space(pos_h, vel_h, BoxSize, Hubble, redshift, axis)\n",
    "#         MASL.MA(pos_h, delta, BoxSize, 'PCS', verbose=False)\n",
    "#         delta /= np.mean(delta)\n",
    "#         delta -= 1.0\n",
    "#         delta_fields.append(delta)\n",
    "#     return delta_fields\n",
    "\n",
    "# # Setup and initialization as before\n",
    "# BoxSize, grid, Hubble, redshift = 1000.0, 256, 100, 0\n",
    "# numbers = list(range(10))\n",
    "# axis_list = [0, 1, 2]\n",
    "# typey, snapnum = 'EQ_m', 4\n",
    "\n",
    "# # Initialize arrays\n",
    "# Pk_z0_arrays = [initialize_arrays(Pks_32_x_s.shape) for _ in range(3)]\n",
    "# Pk_z127_rec_arrays = [initialize_arrays(Pks_32_pred_x_s.shape) for _ in range(3)]\n",
    "# Bk_z0_arrays = [initialize_arrays(Bks_32_x_s.shape) for _ in range(3)]\n",
    "# Bk_z127_rec_arrays = [initialize_arrays(Bks_32_pred_x_s.shape) for _ in range(3)]\n",
    "\n",
    "\n",
    "# # Processing loop\n",
    "# print('loop starts')\n",
    "# for num in numbers:\n",
    "#     print(num)\n",
    "#     snapdir = f'/scratch/hb-CosmoGroup/Quijote_Halos/{typey}/{num}'\n",
    "#     pos_h, vel_h = process_catalog(snapdir, snapnum, BoxSize, grid, redshift, Hubble)\n",
    "#     delta_fields = apply_redshift_space_distortion(pos_h, vel_h, BoxSize, Hubble, redshift, grid, axis_list)\n",
    "#     pks, bks = calculate_spectra(delta_fields, BoxSize, axis_list)\n",
    "\n",
    "#     pks_original, bks_original = calculate_spectra(delta_fields, BoxSize, 2)\n",
    "#     spectra_predicted = predict_and_calculate_spectra(model, params, batch_stats, delta_fields)\n",
    "    \n",
    "#     Pk_z0_array_x[num], Pk_z127_rec_array_x[num] = pks_original[0], spectra_predicted[0][0]\n",
    "#     Pk_z0_array_y[num], Pk_z127_rec_array_y[num] = pks_original[1], spectra_predicted[1][0]\n",
    "#     Pk_z0_array_z[num], Pk_z127_rec_array_z[num] = pks_original[2], spectra_predicted[2][0]\n",
    "    \n",
    "#     Bk_z0_array_x[num], Bk_z127_rec_array_x[num] = bks_original[0], spectra_predicted[0][1]\n",
    "#     Bk_z0_array_y[num], Bk_z127_rec_array_y[num] = bks_original[1], spectra_predicted[1][1]\n",
    "#     Bk_z0_array_z[num], Bk_z127_rec_array_z[num] = bks_original[2], spectra_predicted[2][1]\n",
    "\n",
    "# print('loop done')\n",
    "\n",
    "# Pk_z0_combined = np.concatenate(Pk_z0_arrays, axis=0)\n",
    "# Pk_z127_rec_combined = np.concatenate(Pk_z127_rec_arrays, axis=0)\n",
    "# Bk_z0_combined = np.concatenate(Bk_z0_arrays, axis=0)\n",
    "# Bk_z127_rec_combined = np.concatenate(Bk_z127_rec_arrays, axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6176c8-1806-4f34-90a1-57895d9d8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pk_z0_combined.shape)\n",
    "print(Bk_z127_rec_combined.shape)\n",
    "print(Pk_z127_rec_combined[0])\n",
    "print(Pk_z127_rec_combined[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c2afd0-fb4f-4ec8-9930-c8c40d952ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the spectra data with correct numbers\n",
    "# \n",
    "np.save(f\"/scratch/s3487202/Results/power_spectrum/halo_data_z0_{typey}.npy\", Pk_z0_combined)\n",
    "np.save(f\"/scratch/s3487202/Results/power_spectrum/rec_z127_{typey}.npy\", Pk_z127_rec_combined)\n",
    "np.save(f\"/scratch/s3487202/Results/bispectrum/halo_data_z0_{typey}.npy\", Bk_z0_combined)\n",
    "np.save(f\"/scratch/s3487202/Results/bispectrum/rec_z127_{typey}.npy\", Bk_z127_rec_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c68fd64-7baa-40bb-b102-9c72ffa8efc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 220, 5)\n",
      "(1500, 2276, 8)\n"
     ]
    }
   ],
   "source": [
    "print( Pk_z0_combined.shape)\n",
    "print(Bk_z127_rec_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652acf9c-d803-46b5-a393-67f5014cb8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "jax_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
